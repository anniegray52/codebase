{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "from scipy.sparse.linalg import svds\n",
    "import networkx as nx\n",
    "from copy import deepcopy\n",
    "from scipy import linalg\n",
    "import scipy.stats as stats\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multipartite Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook contains the functions used to deal with multipartite graphs - taken from the work we did with microsoft. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally - the functions will take in and out 2 things: \n",
    "- the matrix or the embedding\n",
    "- attributes: two lists, each a dictionary containing information about the rows/columns respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with own path to data folder:\n",
    "# path = 'path_to_data_folder'\n",
    "# path = '/home/ag16115/Documents/phd/codebase_data/brazil'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finished functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## can handle the lyon example (two columns from the same partition) but need to check if it can handle more advance cases \n",
    "\n",
    "def matrix_from_tables(tables, relationships, time_col=None, join_token='::', multipartite=True):\n",
    "    \"\"\" \n",
    "    Create a DMP graph from a dataframe.    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tables : pandas.DataFrame or list of pandas.DataFrame\n",
    "        The data to be used to create the graph. If a list of dataframes is \n",
    "        passed, each dataframe is used to create a separate graph.\n",
    "    relationships : list of lists\n",
    "        The partition pairs to be used to create the graph. Each element of\n",
    "        the list is a list of two elements, which are the names of the\n",
    "        partitions to be joined.\n",
    "    time_col : str or list of str\n",
    "        The name of the column containing the time information. If a list of\n",
    "        strings is passed, each string is the name of the column containing\n",
    "        the time information for each dataframe in data.\n",
    "    join_token : str\n",
    "        The token used to join the partition name and the node name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A : scipy.sparse.csr_matrix\n",
    "        The adjacency matrix of the graph.  \n",
    "    attributes : list of lists\n",
    "        The attributes of the nodes. The first list contains the attributes\n",
    "        of the nodes that do not change over time. The second list contains\n",
    "        the attributes of the nodes that change over time.\n",
    "    \"\"\"\n",
    "    # Ensure data and relationships are in list format\n",
    "    if not isinstance(tables, list):\n",
    "        tables = [tables]\n",
    "    if not isinstance(relationships[0][0], list):\n",
    "        relationships = [relationships]\n",
    "\n",
    "    # Handle the case when time_col is None\n",
    "    if time_col is None:\n",
    "        time_col = [None] * len(tables)\n",
    "    elif isinstance(time_col, str):\n",
    "        time_col = [time_col] * len(tables)\n",
    "\n",
    "    edge_list = create_edge_list(\n",
    "        tables, relationships, time_col, join_token, multipartite)\n",
    "    nodes, partitions, times, node_ids, time_ids = extract_node_time_info(\n",
    "        edge_list, join_token)\n",
    "\n",
    "    edge_list = transform_edge_data(edge_list, node_ids, time_ids, len(nodes))\n",
    "    A = create_adjacency_matrix(edge_list, len(nodes), len(times))\n",
    "    attributes = create_node_attributes(\n",
    "        nodes, partitions, times, len(nodes), len(times))\n",
    "\n",
    "    return A.tocsr(), attributes\n",
    "\n",
    "\n",
    "def create_edge_list(tables, relationships, time_col, join_token, multipartite):\n",
    "    edge_list = []\n",
    "    for data0, relationships0, time_col0 in zip(tables, relationships, time_col):\n",
    "        for partition_pair in relationships0:\n",
    "            if time_col0:\n",
    "                pair_data = data0[partition_pair +\n",
    "                                  [time_col0]].drop_duplicates()\n",
    "                pair_data['T'] = pair_data[time_col0]\n",
    "                pair_data = pair_data.drop(columns=[time_col0])\n",
    "            else:\n",
    "                pair_data = data0[partition_pair].drop_duplicates()\n",
    "                pair_data['T'] = np.nan\n",
    "            pair_data.columns = ['V1', 'V2', 'T']\n",
    "\n",
    "            if len(intersection(pair_data['V1'],pair_data['V2'])) != 0:\n",
    "                pair_data['V1'] = [\n",
    "                    f\"{partition_pair[0]}{join_token}{x}\" for x in pair_data['V1']]\n",
    "                pair_data['V2'] = [\n",
    "                    f\"{partition_pair[0]}{join_token}{x}\" for x in pair_data['V2']]\n",
    "                pair_data['P1'] = partition_pair[0]\n",
    "                pair_data['P2'] = partition_pair[1]\n",
    "                edge_list.append(pair_data)\n",
    "            else:\n",
    "                pair_data['V1'] = [\n",
    "                    f\"{partition_pair[0]}{join_token}{x}\" for x in pair_data['V1']]\n",
    "                pair_data['V2'] = [\n",
    "                    f\"{partition_pair[1]}{join_token}{x}\" for x in pair_data['V2']]\n",
    "                pair_data['P1'] = partition_pair[0]\n",
    "                pair_data['P2'] = partition_pair[1]\n",
    "                edge_list.append(pair_data)\n",
    "            print(partition_pair)\n",
    "    return pd.concat(edge_list)\n",
    "\n",
    "\n",
    "def extract_node_time_info(edge_list, join_token):\n",
    "    nodes = sorted(set(edge_list['V1']).union(edge_list['V2']))\n",
    "    partitions = [node.split(join_token)[0] for node in nodes]\n",
    "    times = sorted(set(edge_list['T'].unique()))\n",
    "    # times = sorted(set(edge_list['T']))\n",
    "    node_ids = {node: idx for idx, node in enumerate(nodes)}\n",
    "    time_ids = {time: idx for idx, time in enumerate(times)}\n",
    "    return nodes, partitions, times, node_ids, time_ids\n",
    "\n",
    "\n",
    "def transform_edge_data(edge_list, node_ids, time_ids, n_nodes):\n",
    "    edge_list['V_ID1'] = edge_list['V1'].map(node_ids)\n",
    "    edge_list['V_ID2'] = edge_list['V2'].map(node_ids)\n",
    "    edge_list['T_ID'] = edge_list['T'].map(time_ids)\n",
    "    edge_list['X_ID1'] = edge_list['T_ID'] * n_nodes + edge_list['V_ID1']\n",
    "    edge_list['X_ID2'] = edge_list['T_ID'] * n_nodes + edge_list['V_ID2']\n",
    "    return edge_list\n",
    "\n",
    "\n",
    "def create_adjacency_matrix(edge_list, n_nodes, n_times):\n",
    "    row_indices = pd.concat([edge_list['V_ID1'], edge_list['V_ID2']])\n",
    "    col_indices = pd.concat([edge_list['X_ID2'], edge_list['X_ID1']])\n",
    "    values = np.ones(2 * len(edge_list))\n",
    "    return sparse.coo_matrix((values, (row_indices, col_indices)), shape=(n_nodes, n_nodes * n_times))\n",
    "\n",
    "\n",
    "def create_node_attributes(nodes, partitions, times, n_nodes, n_times):\n",
    "    time_attrs = np.repeat(times, n_nodes)\n",
    "    attributes = [\n",
    "        [{'name': name, 'partition': partition, 'time': np.nan}\n",
    "            for name, partition in zip(nodes, partitions)],\n",
    "        [{'name': name, 'partition': partition, 'time': time} for name, partition,\n",
    "            time in zip(nodes * n_times, partitions * n_times, time_attrs)]\n",
    "    ]\n",
    "    return attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realise this may seem like a convoluted way to do this but it'll make it easier to add time element later\n",
    "def find_subgraph(A, attributes, subgraph_attributes):\n",
    "    \"\"\"\n",
    "    Find a subgraph of a multipartite graph.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : scipy.sparse.csr_matrix\n",
    "        The adjacency matrix of the multipartite graph.\n",
    "    attributes : list of lists\n",
    "        The attributes of the nodes. The first list contains the attributes\n",
    "        of the nodes in rows. The second list contains\n",
    "        the attributes of the nodes in the columns.\n",
    "    subgraph_attributes : list of lists\n",
    "        The attributes of the nodes of the wanted in the subgraph. The first list contains\n",
    "        the attributes of the nodes wanted in the rows. The second\n",
    "        list contains the attributes of the nodes wanted in the column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    subgraph_A : scipy.sparse.csr_matrix\n",
    "        The adjacency matrix of the subgraph.\n",
    "    subgraph_attributes : list of lists\n",
    "        The attributes of the nodes of the subgraph. The first list contains\n",
    "        the attributes of the nodes in the rows. The second\n",
    "        list contains the attributes of the nodes in the columns.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(subgraph_attributes[0], list):\n",
    "        subgraph_attributes[0] = [subgraph_attributes[0]]\n",
    "\n",
    "    if not isinstance(subgraph_attributes[1], list):\n",
    "        subgraph_attributes[1] = [subgraph_attributes[1]]\n",
    "\n",
    "    # find the indices of the rows with required attributes\n",
    "    subgraph_node_indices_row = []\n",
    "    for node_idx, node_attributes in enumerate(attributes[0]):\n",
    "        for each_subgraph_attributes in subgraph_attributes[0]:\n",
    "            matched = True\n",
    "            for key, value in each_subgraph_attributes.items():\n",
    "                if key not in node_attributes or node_attributes[key] != value:\n",
    "                    matched = False\n",
    "                    break\n",
    "            if matched:\n",
    "                subgraph_node_indices_row.append(node_idx)\n",
    "\n",
    "    # find the indices of the columns with required attributes\n",
    "    subgraph_node_indices_col = []\n",
    "    for node_idx, node_attributes in enumerate(attributes[1]):\n",
    "        for each_subgraph_attributes in subgraph_attributes[1]:\n",
    "            matched = True\n",
    "            for key, value in each_subgraph_attributes.items():\n",
    "                if key not in node_attributes or node_attributes[key] != value:\n",
    "                    matched = False\n",
    "                    break\n",
    "            if matched:\n",
    "                subgraph_node_indices_col.append(node_idx)\n",
    "\n",
    "    # create subgraph and subgraph attributes\n",
    "    subgraph_A = A[np.ix_(subgraph_node_indices_row,\n",
    "                          subgraph_node_indices_col)]\n",
    "    subgraph_attributes = [[attributes[0][i] for i in subgraph_node_indices_row], [\n",
    "        attributes[1][i] for i in subgraph_node_indices_col]]\n",
    "\n",
    "    return subgraph_A, subgraph_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_matrix(m, n = None):\n",
    "    \"\"\"\n",
    "    Create a zero matrix.\n",
    "    \"\"\"\n",
    "    if n == None:\n",
    "        n = m\n",
    "    M = sparse.coo_matrix(([],([],[])),shape = (m,n))\n",
    "    return M\n",
    "\n",
    "def symmetric_dilation(M):\n",
    "    \"\"\"\n",
    "    Dilate a matrix to a symmetric matrix.\n",
    "    \"\"\"\n",
    "    m, n = M.shape\n",
    "    D = sparse.vstack([sparse.hstack([zero_matrix(m), M]), sparse.hstack([M.T, zero_matrix(n)])])\n",
    "    return D\n",
    "\n",
    "def subgraph_idx(A, attributes, idx0, idx1):\n",
    "    \"\"\"\n",
    "    Find a subgraph of a multipartite graph by indices.\n",
    "    \"\"\"  \n",
    "    subgraph_A = A[np.ix_(idx0, idx1)]\n",
    "    subgraph_attributes = [\n",
    "        [attributes[0][i] for i in idx0],\n",
    "        [attributes[1][i] for i in idx1]\n",
    "    ]\n",
    "    return subgraph_A, subgraph_attributes\n",
    "\n",
    "## check what happens when repeated partition in row and column\n",
    "def find_connected_components(A, attributes, n_components = 1):\n",
    "    \"\"\"\n",
    "    Find connected components of a multipartite graph.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : scipy.sparse.csr_matrix\n",
    "        The adjacency matrix of the graph.\n",
    "    attributes : list of lists\n",
    "        The attributes of the nodes. The first list contains the attributes\n",
    "        of the nodes in rows. The second list contains\n",
    "        the attributes of the nodes in the columns.\n",
    "    n_components : int\n",
    "        The number of components to be found.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cc_As : list of scipy.sparse.csr_matrix\n",
    "        The adjacency matrices of the connected components.\n",
    "    cc_attributes : list of lists\n",
    "        The attributes of the nodes of the connected components. The first list contains\n",
    "        the attributes of the nodes in the rows. The second\n",
    "        list contains the attributes of the nodes in the columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    A_dilation = symmetric_dilation(A)\n",
    "    _, cc = connected_components(A_dilation)\n",
    "    cc = [cc[:A.shape[0]], cc[A.shape[0]:]]\n",
    "    if n_components == None:\n",
    "        n_components = np.max(cc) + 1\n",
    "    else:\n",
    "        cc_As = []\n",
    "        cc_attributes = []\n",
    "        for i in range(n_components):\n",
    "            idx0 = np.where(cc[0] == i)[0]\n",
    "            idx1 = np.where(cc[1] == i)[0]\n",
    "            store_cc_A, store_cc_attributes = subgraph_idx(A,attributes, idx0, idx1)\n",
    "            cc_As.append(store_cc_A)\n",
    "            cc_attributes.append(store_cc_attributes)\n",
    "        if len(cc_As) == 1:\n",
    "            cc_As = cc_As[0]\n",
    "            cc_attributes = cc_attributes[0]\n",
    "        return cc_As, cc_attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_networkx(A, attributes, symmetric=None):\n",
    "    \"\"\" \n",
    "    Convert a multipartite graph to a networkx graph.\n",
    "    \"\"\"\n",
    "    if symmetric == None:\n",
    "        if is_symmetric(A):\n",
    "            symmetric = True\n",
    "        else:\n",
    "            symmetric = False\n",
    "    if symmetric:\n",
    "        G_nx = nx.Graph(A)\n",
    "        nx.set_node_attributes(G_nx, {i: a for i, a in enumerate(attributes[0])})\n",
    "        return G_nx\n",
    "    else:\n",
    "        n0 = len(attributes[0])\n",
    "        n1 = len(attributes[1])\n",
    "        G_nx = nx.Graph(symmetric_dilation(A))\n",
    "        nx.set_node_attributes(G_nx, {i: a for i, a in enumerate(attributes[0])})\n",
    "        nx.set_node_attributes(G_nx, {i + n0: a for i, a in enumerate(attributes[1])})\n",
    "        nx.set_node_attributes(G_nx, {i: {'bipartite': 0} for i in range(n0)})\n",
    "        nx.set_node_attributes(G_nx, {i + n0: {'bipartite': 1} for i in range(n1)})\n",
    "        return G_nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_select(A, plot=True, plotrange=50):\n",
    "    ## NEEDS UPDATING FOR DILATED MATRIX ##\n",
    "    \"\"\" \n",
    "    Select the number of dimensions for A.\n",
    "    Finding a changepoint using the likelihood profile (Zhu, Ghodsi; 2006).\n",
    "\n",
    "    Parameters\n",
    "    ----------  \n",
    "    As : numpy.array\n",
    "        The array of matrices.\n",
    "    plot : bool\n",
    "        Whether to plot the singular values and the likelihood profile.\n",
    "    plotrange : int\n",
    "        The range of dimensions to be plotted.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lq_best : int\n",
    "        The number of dimensions selected.\n",
    "    \"\"\"   \n",
    "    if scipy.sparse.issparse(A):\n",
    "        A = A.todense()\n",
    "\n",
    "    # # Construct rectangular matrices\n",
    "    # if len(As.shape) == 2:\n",
    "    #     As = np.array([As[:,:]])\n",
    "    \n",
    "    # if len(As.shape) == 3:\n",
    "    #     T = len(As)\n",
    "    #     A = As[0,:,:]\n",
    "    #     for t in range(1,T):\n",
    "    #         A = np.block([A,As[t]])\n",
    "            \n",
    "    UA, SA, VAt = np.linalg.svd(A)\n",
    "    \n",
    "    # Compute likelihood profile\n",
    "    n = len(SA)\n",
    "    lq = np.zeros(n); lq[0] = 'nan'\n",
    "    for q in range(1,n):\n",
    "        theta_0 = np.mean(SA[:q])\n",
    "        theta_1 = np.mean(SA[q:])\n",
    "        sigma = np.sqrt(((q-1)*np.var(SA[:q]) + (n-q-1)*np.var(SA[q:])) / (n-2))\n",
    "        lq_0 = np.sum(np.log(stats.norm.pdf(SA[:q], theta_0, sigma)))\n",
    "        lq_1 = np.sum(np.log(stats.norm.pdf(SA[q:], theta_1, sigma)))\n",
    "        lq[q] = lq_0 +lq_1    \n",
    "    lq_best = np.nanargmax(lq)\n",
    "\n",
    "    if plot:\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(12.0,4.0))\n",
    "        plt.subplots_adjust(hspace = 0.3)\n",
    "        \n",
    "        axs[0].plot(range(plotrange), SA[:plotrange], '.-')\n",
    "        axs[0].set_title('Singular values')\n",
    "        axs[0].set_xlabel('Number of dimensions')\n",
    "        axs[0].axvline(x=lq_best, ls='--', c='k')\n",
    "\n",
    "        axs[1].plot(range(plotrange), lq[:plotrange], '.-')\n",
    "        axs[1].set_title('Log likelihood')\n",
    "        axs[1].set_xlabel('Number of dimensions')\n",
    "        axs[1].axvline(x=lq_best, ls='--', c='k');\n",
    "        \n",
    "    return lq_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_inv_sqrt(a, tol=1e-12):\n",
    "    \"\"\"\n",
    "    Compute the inverse square root of an array, ignoring division by zero.\n",
    "    \"\"\"\n",
    "    with np.errstate(divide=\"ignore\"):\n",
    "        b = 1 / np.sqrt(a)\n",
    "    b[np.isinf(b)] = 0\n",
    "    b[a < tol] = 0\n",
    "    return b\n",
    "\n",
    "def to_laplacian(A, regulariser=0):\n",
    "    \"\"\"\n",
    "    Convert an adjacency matrix to a Laplacian matrix.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : scipy.sparse.csr_matrix\n",
    "        The adjacency matrix.\n",
    "    regulariser : float\n",
    "        The regulariser to be added to the degrees of the nodes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    L : scipy.sparse.csr_matrix\n",
    "        The Laplacian matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    left_degrees = np.reshape(np.asarray(A.sum(axis=1)), (-1,))\n",
    "    right_degrees = np.reshape(np.asarray(A.sum(axis=0)), (-1,))\n",
    "    if regulariser == 'auto':\n",
    "        regulariser = np.mean(np.concatenate((left_degrees, right_degrees)))\n",
    "    left_degrees_inv_sqrt = safe_inv_sqrt(left_degrees + regulariser)\n",
    "    right_degrees_inv_sqrt = safe_inv_sqrt(right_degrees + regulariser)\n",
    "    L = sparse.diags(left_degrees_inv_sqrt) @ A @ sparse.diags(right_degrees_inv_sqrt)\n",
    "    return L\n",
    "\n",
    "def embed(A, d = 10, matrix = 'adjacency', regulariser = 0):\n",
    "    \"\"\" \n",
    "    Embed a graph using the laplacian or adjacency matrix.  \n",
    "\n",
    "    Parameters  \n",
    "    ----------  \n",
    "    A : scipy.sparse.csr_matrix  \n",
    "        The adjacency matrix of the graph.  \n",
    "    d : int \n",
    "        The dimension of the embedding.\n",
    "    matrix : str    \n",
    "        The matrix to be used for embedding.\n",
    "    regulariser : float \n",
    "        The regulariser to be added to the degrees of the nodes (if matrix = 'laplacian' used).    \n",
    "\n",
    "    Returns \n",
    "    ------- \n",
    "    left_embedding : numpy.ndarray \n",
    "        The left embedding of the graph.    \n",
    "    right_embedding : numpy.ndarray \n",
    "        The right embedding of the graph.    \n",
    "    \"\"\"\n",
    "\n",
    "    if matrix == 'laplacian':\n",
    "        L = to_laplacian(A, regulariser)\n",
    "        u, s, vT = svds(L, d)\n",
    "    else:\n",
    "        u, s, vT = svds(A, d)\n",
    "    o = np.argsort(s[::-1])\n",
    "    left_embedding = u[:,o] @ np.diag(np.sqrt(s[o]))\n",
    "    right_embedding = vT.T[:,o] @ np.diag(np.sqrt(s[o]))                      \n",
    "    return left_embedding, right_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## post embedding functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_symmetric(m):\n",
    "    \"\"\"Check if a sparse matrix is symmetric\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    m : array or sparse matrix\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    check : bool\n",
    "        The check result.\n",
    "\n",
    "    \"\"\"\n",
    "    if m.shape[0] != m.shape[1]:\n",
    "        return False\n",
    "\n",
    "    if not isinstance(m, sparse.coo_matrix):\n",
    "        m = sparse.coo_matrix(m)\n",
    "\n",
    "    r, c, v = m.row, m.col, m.data\n",
    "    tril_no_diag = r > c\n",
    "    triu_no_diag = c > r\n",
    "\n",
    "    if triu_no_diag.sum() != tril_no_diag.sum():\n",
    "        return False\n",
    "\n",
    "    rl = r[tril_no_diag]\n",
    "    cl = c[tril_no_diag]\n",
    "    vl = v[tril_no_diag]\n",
    "    ru = r[triu_no_diag]\n",
    "    cu = c[triu_no_diag]\n",
    "    vu = v[triu_no_diag]\n",
    "\n",
    "    sortl = np.lexsort((cl, rl))\n",
    "    sortu = np.lexsort((ru, cu))\n",
    "    vl = vl[sortl]\n",
    "    vu = vu[sortu]\n",
    "\n",
    "    check = np.allclose(vl, vu)\n",
    "\n",
    "    return check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_subspaces(embedding, attributes):\n",
    "    \"\"\"\n",
    "    Recover the subspaces for each partition from an embedding.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    embedding : numpy.ndarray\n",
    "        The embedding of the graph.\n",
    "    attributes : list of lists\n",
    "        The attributes of the nodes. The first list contains the attributes\n",
    "        of the nodes in rows. The second list contains\n",
    "        the attributes of the nodes in the columns.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    partition_embeddings : dict\n",
    "        The embeddings of the partitions.\n",
    "    partition_attributes : dict\n",
    "        The attributes of the nodes in the partitions.\n",
    "    \"\"\"\n",
    "\n",
    "    partitions = list(set([x['partition'] for x in attributes]))\n",
    "    partition_embeddings = {}\n",
    "    partition_attributes = {}\n",
    "    for p in partitions:\n",
    "        p_embedding, p_attributes = select(embedding,attributes, {'partition': p})\n",
    "        Y = p_embedding\n",
    "        u, s, vT = linalg.svd(Y, full_matrices=False)\n",
    "        o = np.argsort(s[::-1])\n",
    "        Y = Y @ vT.T[:, o]\n",
    "        partition_embeddings[p] = Y\n",
    "        partition_attributes[p] = p_attributes\n",
    "    return partition_embeddings, partition_attributes\n",
    "\n",
    "def select(embedding, attributes, select_attributes):\n",
    "    \"\"\"\n",
    "    Select portion of embedding and attributes associated with a set of attributes.\n",
    "    \"\"\"\n",
    "    if not isinstance(select_attributes, list):\n",
    "        select_attributes = [select_attributes]\n",
    "    which_nodes = list()\n",
    "    for attributes_dict in select_attributes:\n",
    "        for a, v in attributes_dict.items():\n",
    "            if not isinstance(v, list):\n",
    "                v = [v]\n",
    "        which_nodes_by_attribute = [[i for i, y in enumerate(attributes) if y[a] in v] for a, v in attributes_dict.items()]\n",
    "        which_nodes.append(list(set.intersection(*map(set, which_nodes_by_attribute))))\n",
    "    which_nodes = list(set().union(*which_nodes))\n",
    "    selected_X = embedding[which_nodes, :]\n",
    "    selected_attributes = [attributes[i] for i in which_nodes]\n",
    "    return selected_X, selected_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate(X, d):\n",
    "    \"\"\"\n",
    "    Truncate an embedding to a lower dimension.\n",
    "    \"\"\"\n",
    "    Y = X[:, :d]\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree_correction(X):\n",
    "    \"\"\"\n",
    "    Perform degree correction.\n",
    "    \"\"\"\n",
    "    tol = 1e-12\n",
    "    Y = deepcopy(X)\n",
    "    norms = np.linalg.norm(X, axis=1)\n",
    "    idx = np.where(norms > tol)\n",
    "    Y[idx] = X[idx] / (norms[idx, None])\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dynamic - lyon school "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "# need the activity_data.csv file\n",
    "path = '/home/ag16115/Documents/phd/codebase_data/'\n",
    "data = pd.read_csv(path + 'ia-primary-school-proximity-attr.edges', sep = ',', on_bad_lines='skip', header = None)\n",
    "# data = pd.read_csv(path + '/activity_data.csv', sep = '\\t', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rename columns   \n",
    "data.columns = ['V1', 'V2', 'T', 'L1', 'L2']\n",
    "## sort out time column\n",
    "data['H'] = [int(int(t)/(60*60)) for t in list(data['T'])]\n",
    "data['D'] = [int(int(t)/(60*60*24)) for t in list(data['T'])]\n",
    "data['T1'] = [10*int(i/24) + i%24 - 8 for i in list(data['H'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the intersection of two lists   \n",
    "def intersection(lst1, lst2): \n",
    "    return list(set(lst1) & set(lst2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the union of two lists  \n",
    "def union(lst1, lst2): \n",
    "    final_list = list(set(lst1) | set(lst2)) \n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(union(data['V1'],data['V2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(intersection(data['V1'],data['V2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V1', 'V2']\n"
     ]
    }
   ],
   "source": [
    "A, attributes = matrix_from_tables(data, [['V1', 'V2']], time_col = 'T1', join_token='::', multipartite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = ['data1','data2','data2']\n",
    "time_col = ['T1','T2','T3']\n",
    "relationships = [['V1', 'V2'],['V2', 'V3']]\n",
    "\n",
    "if not isinstance(tables, list):\n",
    "    tables = [tables]\n",
    "if not isinstance(relationships[0][0], list):\n",
    "    relationships = [relationships]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data1', [['V1', 'V2'], ['V2', 'V3']], 'T1'),\n",
       " ('data1', [['V1', 'V2'], ['V2', 'V3']], 'T2'),\n",
       " ('data1', [['V1', 'V2'], ['V2', 'V3']], 'T3'),\n",
       " ('data2', [['V1', 'V2'], ['V2', 'V3']], 'T1'),\n",
       " ('data2', [['V1', 'V2'], ['V2', 'V3']], 'T2'),\n",
       " ('data2', [['V1', 'V2'], ['V2', 'V3']], 'T3'),\n",
       " ('data2', [['V1', 'V2'], ['V2', 'V3']], 'T1'),\n",
       " ('data2', [['V1', 'V2'], ['V2', 'V3']], 'T2'),\n",
       " ('data2', [['V1', 'V2'], ['V2', 'V3']], 'T3')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "list(itertools.product(tables,relationships,time_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(combinations(tables,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1 ['V1', 'V2'] T1\n",
      "data2 ['V2', 'V3'] T2\n"
     ]
    }
   ],
   "source": [
    "for data0, relationships0, time_col0 in zip(tables, relationships, time_col):\n",
    "    print(data0, relationships0, time_col0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data1', [['V1', 'V2'], ['V2', 'V3']], 'T1')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(tables, relationships, time_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(242, 4840)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "UA, SA, VAt = scipy.sparse.linalg.svds(A,k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scree_plot(A, s = 1, vline=None):\n",
    "    UA, SA, VAt = scipy.sparse.linalg.svds(A,k=50)\n",
    "    SA = SA[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scree_plot(A, k = 50, s = 10, vline=None):\n",
    "    UA, SA, VAt = scipy.sparse.linalg.svds(A,k=k)\n",
    "    fig=plt.figure(figsize=(8,6), dpi= 100, facecolor='w', edgecolor='k')\n",
    "    plt.scatter(range(len(SA)), np.sort(SA)[::-1], s =s)\n",
    "    if vline:\n",
    "        plt.axvline(x=vline, color='green', linewidth=0.5)\n",
    "        \n",
    "# def subspace_scree_plots(embeddings, s = 1, vlines=None):\n",
    "#     fig, axs = plt.subplots(len(embeddings), figsize=(12,4*len(embeddings)))\n",
    "#     fig.patch.set_facecolor('white')\n",
    "#     for i, p in enumerate(embeddings.keys()):\n",
    "#         axs[i].title.set_text(p)\n",
    "#         axs[i].scatter(range(len(embeddings[p].metadata['partition singular values'])), np.sort(embeddings[p].metadata['partition singular values'])[::-1], s =s)\n",
    "#         if vlines:\n",
    "#             axs[i].axvline(x=vlines[i], color='green', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scree_plot(A, k = 50,s = 10, vline=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multipartite - brazil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains information about the procurement process in Brazil. Each row contains information about a tender with information:\n",
    "- Tender: tender id\n",
    "- Period: time \n",
    "- Buyer: who is funding\n",
    "- Item: what the tender is abour \n",
    "- Company: who has bid for the tender\n",
    "- bidder_win: whether the bid was won or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24841/835500605.py:1: DtypeWarning: Columns (13,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(path + 'brazil/activity_data.csv', sep = '\\t', on_bad_lines='skip')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Company', 'Tender']\n",
      "['Company', 'Buyer']\n",
      "['Company', 'Item']\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(path + 'brazil/activity_data.csv', sep = '\\t', on_bad_lines='skip')\n",
    "A, attributes = matrix_from_tables(data, [['Company', 'Tender'],['Company', 'Buyer'],['Company', 'Item']], join_token='::')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find subgraph wanted\n",
    "\n",
    "subgraph_attributes = [\n",
    "    [{'partition': 'Company'},{'partition': 'Tender'}],\n",
    "    {'partition': 'Buyer'}\n",
    "]\n",
    "\n",
    "# subgraph_attributes = [\n",
    "#     {'partition': 'Company'},\n",
    "#     {'partition': 'Buyer'}\n",
    "# ]\n",
    "subgraph_A, subgraph_attributes  = find_subgraph(A, attributes,subgraph_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A_dilation = symmetric_dilation(subgraph_A)\n",
    "# is_symmetric(A_dilation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the largest connected component\n",
    "cc_A, cc_attributes = find_connected_components(subgraph_A, subgraph_attributes,n_components = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G = to_networkx(cc_A, cc_attributes)\n",
    "# G.number_of_nodes()\n",
    "# G.nodes[1]\n",
    "# list(G.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get left and right embeddings\n",
    "left_embed, right_embed = embed(cc_A, matrix = 'laplacian')\n",
    "# the attributes associated with left_embed and right_embed are cc_attributes[0] and cc_attributes[1]\n",
    "left_attributes = cc_attributes[0]\n",
    "right_attributes = cc_attributes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_embeddings, partition_attributes = recover_subspaces(left_embed,left_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_embeddings['Company'] = degree_correction(partition_embeddings['Company'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
