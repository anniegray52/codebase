{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ag16115/anaconda3/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finished functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_from_dataframe(data, partition_pairs, join_token='::'):\n",
    "    \"\"\"\n",
    "    Create a DMP graph from a dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pandas.DataFrame or list of pandas.DataFrame\n",
    "        The data to be used to create the graph. If a list of dataframes is\n",
    "        passed, each dataframe is used to create a separate graph.\n",
    "    partition_pairs : list of lists\n",
    "        The partition pairs to be used to create the graph. Each element of\n",
    "        the list is a list of two elements, which are the names of the\n",
    "        partitions to be joined.\n",
    "    join_token : str\n",
    "        The token used to join the partition name and the node name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A : scipy.sparse.csr_matrix\n",
    "        The adjacency matrix of the graph.\n",
    "    attributes : list of lists\n",
    "        The attributes of the nodes. The first list contains the attributes\n",
    "        of the nodes that do not change over time. The second list contains\n",
    "        the attributes of the nodes that change over time.\n",
    "    \"\"\"\n",
    "    if not isinstance(data, list):\n",
    "        data = [data]\n",
    "    if not isinstance(partition_pairs[0][0], list):\n",
    "        partition_pairs = [partition_pairs]\n",
    "        \n",
    "    edge_list = []\n",
    "    for data0, partition_pairs0 in zip(data, partition_pairs):\n",
    "        for partition_pair in partition_pairs0:\n",
    "            pair_data = data0[partition_pair].drop_duplicates()\n",
    "            pair_data.columns = ['V1', 'V2']\n",
    "            pair_data['V1'] = [partition_pair[0] + join_token + str(x) for x in pair_data['V1']]\n",
    "            pair_data['V2'] = [partition_pair[1] + join_token + str(x) for x in pair_data['V2']]\n",
    "            pair_data['P1'] = partition_pair[0]\n",
    "            pair_data['P2'] = partition_pair[1]\n",
    "            edge_list.append(pair_data)\n",
    "            \n",
    "    edge_list = pd.concat(edge_list)\n",
    "    nodes = sorted(list(set(list(edge_list['V1']) + list(edge_list['V2']))))\n",
    "    node_ids = {x: i for i, x in enumerate(nodes)}\n",
    "    partitions = [str.split(x, join_token)[0] for x in nodes]\n",
    "    n_nodes = len(nodes)\n",
    "    \n",
    "    edge_list['V_ID1'] = [node_ids[x] for x in edge_list['V1']]\n",
    "    edge_list['V_ID2'] = [node_ids[x] for x in edge_list['V2']]\n",
    "    \n",
    "    A = sparse.coo_matrix((np.ones(2*len(edge_list)),\n",
    "                    (pd.concat([edge_list['V_ID1'], edge_list['V_ID2']]),\n",
    "                     pd.concat([edge_list['V_ID2'], edge_list['V_ID1']]))),\n",
    "                    shape=[n_nodes, n_nodes])\n",
    "    \n",
    "    attributes = [[{'name': name, 'partition': partition} for name, partition in zip(nodes, partitions)]] * 2\n",
    "\n",
    "    A = A.tocsr()\n",
    "    return A, attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realise this may seem like a convoluted way to do this but it'll make it easier to add time element later\n",
    "def find_subgraph(A, attributes, subgraph_attributes):\n",
    "    \"\"\"\n",
    "    Find a subgraph of a multipartite graph.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : scipy.sparse.csr_matrix\n",
    "        The adjacency matrix of the multipartite graph.\n",
    "    attributes : list of lists\n",
    "        The attributes of the nodes. The first list contains the attributes\n",
    "        of the nodes in rows. The second list contains\n",
    "        the attributes of the nodes in the columns.\n",
    "    subgraph_attributes : list of lists\n",
    "        The attributes of the nodes of the wanted in the subgraph. The first list contains\n",
    "        the attributes of the nodes wanted in the rows. The second\n",
    "        list contains the attributes of the nodes wanted in the column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    subgraph_A : scipy.sparse.csr_matrix\n",
    "        The adjacency matrix of the subgraph.\n",
    "    subgraph_attributes : list of lists\n",
    "        The attributes of the nodes of the subgraph. The first list contains\n",
    "        the attributes of the nodes in the rows. The second\n",
    "        list contains the attributes of the nodes in the columns.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(subgraph_attributes[0], list):\n",
    "        subgraph_attributes[0] = [subgraph_attributes[0]]\n",
    "\n",
    "    if not isinstance(subgraph_attributes[1], list):\n",
    "        subgraph_attributes[1] = [subgraph_attributes[1]]\n",
    "\n",
    "    # find the indices of the rows with required attributes\n",
    "    subgraph_node_indices_row = []\n",
    "    for node_idx, node_attributes in enumerate(attributes[0]):\n",
    "        for each_subgraph_attributes in subgraph_attributes[0]:\n",
    "            matched = True\n",
    "            for key, value in each_subgraph_attributes.items():\n",
    "                if key not in node_attributes or node_attributes[key] != value:\n",
    "                    matched = False\n",
    "                    break\n",
    "            if matched:\n",
    "                subgraph_node_indices_row.append(node_idx)\n",
    "\n",
    "    # find the indices of the columns with required attributes\n",
    "    subgraph_node_indices_col = []\n",
    "    for node_idx, node_attributes in enumerate(attributes[1]):\n",
    "        for each_subgraph_attributes in subgraph_attributes[1]:\n",
    "            matched = True\n",
    "            for key, value in each_subgraph_attributes.items():\n",
    "                if key not in node_attributes or node_attributes[key] != value:\n",
    "                    matched = False\n",
    "                    break\n",
    "            if matched:\n",
    "                subgraph_node_indices_col.append(node_idx)\n",
    "\n",
    "    # create subgraph and subgraph attributes\n",
    "    subgraph_A = A[np.ix_(subgraph_node_indices_row,\n",
    "                          subgraph_node_indices_col)]\n",
    "    subgraph_attributes = [[attributes[0][i] for i in subgraph_node_indices_row], [\n",
    "        attributes[1][i] for i in subgraph_node_indices_col]]\n",
    "\n",
    "    return subgraph_A, subgraph_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_matrix(m, n = None):\n",
    "    \"\"\"\n",
    "    Create a zero matrix.\n",
    "    \"\"\"\n",
    "    if n == None:\n",
    "        n = m\n",
    "    M = sparse.coo_matrix(([],([],[])),shape = (m,n))\n",
    "    return M\n",
    "\n",
    "def symmetric_dilation(M):\n",
    "    \"\"\"\n",
    "    Dilate a matrix to a symmetric matrix.\n",
    "    \"\"\"\n",
    "    m, n = M.shape\n",
    "    D = sparse.vstack([sparse.hstack([zero_matrix(m), M]), sparse.hstack([M.T, zero_matrix(n)])])\n",
    "    return D\n",
    "\n",
    "def find_connected_components(A, attributes, n_components = 1):\n",
    "    \"\"\"\n",
    "    Find connected components of a multipartite graph.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : scipy.sparse.csr_matrix\n",
    "        The adjacency matrix of the graph.\n",
    "    attributes : list of lists\n",
    "        The attributes of the nodes. The first list contains the attributes\n",
    "        of the nodes in rows. The second list contains\n",
    "        the attributes of the nodes in the columns.\n",
    "    n_components : int\n",
    "        The number of components to be found.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cc_As : list of scipy.sparse.csr_matrix\n",
    "        The adjacency matrices of the connected components.\n",
    "    cc_attributes : list of lists\n",
    "        The attributes of the nodes of the connected components. The first list contains\n",
    "        the attributes of the nodes in the rows. The second\n",
    "        list contains the attributes of the nodes in the columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    A_dilation = symmetric_dilation(A)\n",
    "    _, cc = connected_components(A_dilation)\n",
    "    cc = [cc[:A.shape[0]], cc[A.shape[0]:]]\n",
    "    if n_components == None:\n",
    "        n_components = np.max(cc) + 1\n",
    "    if _ == 1:\n",
    "        return A, attributes\n",
    "    else:\n",
    "        cc_As = []\n",
    "        cc_attributes = []\n",
    "        for i in range(n_components):\n",
    "            idx0 = np.where(cc[0] == i)[0]\n",
    "            idx1 = np.where(cc[1] == i)[0]\n",
    "            store_cc_A, store_cc_attributes = subgraph_idx(A,attributes, idx0, idx1)\n",
    "            cc_As.append(store_cc_A)\n",
    "            cc_attributes.append(store_cc_attributes)\n",
    "        return cc_As, cc_attributes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# need to sort out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_inv_sqrt(a, tol=1e-12):\n",
    "    \"\"\"\n",
    "    Compute the inverse square root of an array, ignoring division by zero.\n",
    "    \"\"\"\n",
    "    with np.errstate(divide=\"ignore\"):\n",
    "        b = 1 / np.sqrt(a)\n",
    "    b[np.isinf(b)] = 0\n",
    "    b[a < tol] = 0\n",
    "    return b\n",
    "\n",
    "def to_laplacian(A, regulariser=0):\n",
    "    \"\"\"\n",
    "    Convert an adjacency matrix to a Laplacian matrix.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : scipy.sparse.csr_matrix\n",
    "        The adjacency matrix.\n",
    "    regulariser : float\n",
    "        The regulariser to be added to the degrees of the nodes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    L : scipy.sparse.csr_matrix\n",
    "        The Laplacian matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    left_degrees = np.reshape(np.asarray(A.sum(axis=1)), (-1,))\n",
    "    right_degrees = np.reshape(np.asarray(A.sum(axis=0)), (-1,))\n",
    "    if regulariser == 'auto':\n",
    "        regulariser = np.mean(np.concatenate((left_degrees, right_degrees)))\n",
    "    left_degrees_inv_sqrt = safe_inv_sqrt(left_degrees + regulariser)\n",
    "    right_degrees_inv_sqrt = safe_inv_sqrt(right_degrees + regulariser)\n",
    "    L = sparse.diags(left_degrees_inv_sqrt) @ A @ sparse.diags(right_degrees_inv_sqrt)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(G, d = 10, matrix = 'adjacency', regulariser = 0):\n",
    "    if matrix == 'laplacian':\n",
    "        L = to_laplacian(G.A, regulariser)\n",
    "        u, s, vT = svds(L, d)\n",
    "    else:\n",
    "        u, s, vT = svds(G.A, d)\n",
    "    o = np.argsort(s[::-1])\n",
    "    X = u[:,o] @ np.diag(np.sqrt(s[o]))\n",
    "    Y = vT.T[:,o] @ np.diag(np.sqrt(s[o]))\n",
    "    left_embedding = Embedding(X,\n",
    "                               attributes = deepcopy(G.attributes[0]),\n",
    "                               metadata = {'singular values': s[o]})\n",
    "    right_embedding = Embedding(Y,\n",
    "                                attributes = deepcopy(G.attributes[1]),\n",
    "                                metadata = {'singular values': s[o]})                                  \n",
    "    return left_embedding, right_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate(X, d, inplace=False):\n",
    "    if inplace:\n",
    "        Y = X\n",
    "    else:\n",
    "        Y = deepcopy(X)\n",
    "    Y.X = Y.X[:, :d]\n",
    "    return Y\n",
    "\n",
    "def select(embedding, attributes, inplace=False):\n",
    "    if not isinstance(attributes, list):\n",
    "        attributes = [attributes]\n",
    "    which_nodes = list()\n",
    "    for attributes_dict in attributes:\n",
    "        for a, v in attributes_dict.items():\n",
    "            if not isinstance(v, list):\n",
    "                v = [v]\n",
    "        which_nodes_by_attribute = [[i for i, y in enumerate(embedding.attributes) if y[a] in v] for a, v in attributes_dict.items()]\n",
    "        which_nodes.append(list(set.intersection(*map(set, which_nodes_by_attribute))))\n",
    "    which_nodes = list(set().union(*which_nodes))\n",
    "    if inplace:\n",
    "        embedding.X = embedding.X[which_nodes, :]\n",
    "        embedding.attributes = [embedding.attributes[i] for i in which_nodes]\n",
    "        return None\n",
    "    else:\n",
    "        selected_X = embedding.X[which_nodes, :]\n",
    "        selected_attributes = [embedding.attributes[i] for i in which_nodes]\n",
    "        selected = Embedding(deepcopy(selected_X), deepcopy(selected_attributes), deepcopy(embedding.metadata))\n",
    "        return selected\n",
    "\n",
    "def recover_subspaces(embedding):    \n",
    "    partitions = list(set([x['partition'] for x in embedding.attributes]))\n",
    "    partition_embeddings = {}\n",
    "    for p in partitions:\n",
    "        p_embedding = select(embedding, {'partition': p})\n",
    "        Y = p_embedding.X\n",
    "        u, s, vT = linalg.svd(Y, full_matrices=False)\n",
    "        o = np.argsort(s[::-1])\n",
    "        Y = Y @ vT.T[:, o]\n",
    "        p_embedding.X = Y\n",
    "        p_embedding.metadata['partition singular values'] = s[o]\n",
    "        partition_embeddings[p] = p_embedding\n",
    "    return partition_embeddings\n",
    "\n",
    "def degree_correction(X, inplace=False):\n",
    "    tol = 1e-12\n",
    "    if inplace:\n",
    "        Y = X\n",
    "    else:\n",
    "        Y = deepcopy(X)\n",
    "    norms = np.linalg.norm(Y.X, axis=1)\n",
    "    idx = np.where(norms > tol)\n",
    "    Y.X[idx] = Y.X[idx] / (norms[idx, None])\n",
    "    return Y\n",
    "\n",
    "class Embedding:\n",
    "    def __init__(self, X, attributes={}, metadata={}):\n",
    "        self.X = X\n",
    "        self.attributes = attributes\n",
    "        self.metadata = metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "from copy import deepcopy\n",
    "\n",
    "def subgraph_idx(A, attributes, idx0, idx1):\n",
    "    \"\"\"\n",
    "    Find a subgraph of a multipartite graph by indices.\n",
    "    \"\"\"  \n",
    "    subgraph_A = A[np.ix_(idx0, idx1)]\n",
    "    subgraph_attributes = [\n",
    "        [attributes[0][i] for i in idx0],\n",
    "        [attributes[1][i] for i in idx1]\n",
    "    ]\n",
    "    return subgraph_A, subgraph_attributes\n",
    "\n",
    "def symmetric_dilation(A):\n",
    "    \"\"\"\n",
    "    Dilate a graph to a symmetric graph.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : scipy.sparse.csr_matrix\n",
    "        The adjacency matrix of the graph.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    A_dilation : scipy.sparse.csr_matrix\n",
    "        The adjacency matrix of the symmetric graph.\n",
    "    \"\"\"\n",
    "\n",
    "    return A + A.T\n",
    "\n",
    "# def connected_components(A, n_components = 1):\n",
    "#     A_dilation = symmetric_dilation(A)\n",
    "#     _, cc = connected_components(A_dilation)\n",
    "#     cc = [cc[:A.shape[0]], cc[A.shape[0]:]]\n",
    "#     if n_components == None:\n",
    "#         n_components = np.max(cc) + 1\n",
    "#     Gcc = []\n",
    "#     for i in range(n_components):\n",
    "#         idx0 = np.where(cc[0] == i)[0]\n",
    "#         idx1 = np.where(cc[1] == i)[0]\n",
    "#         Gcc.append(subgraph_idx(A, idx0, idx1))\n",
    "#     return Gcc\n",
    "\n",
    "\n",
    "def to_networkx(A, attributes, symmetric=None):\n",
    "    if symmetric == None:\n",
    "        if is_symmetric(A):\n",
    "            symmetric = True\n",
    "        else:\n",
    "            symmetric = False\n",
    "    if symmetric:\n",
    "        G_nx = nx.Graph(A)\n",
    "        nx.set_node_attributes(G_nx, {i: a for i, a in enumerate(attributes[0])})\n",
    "        return G_nx\n",
    "    else:\n",
    "        n0 = len(attributes[0])\n",
    "        n1 = len(attributes[1])\n",
    "        G_nx = nx.Graph(symmetric_dilation(A))\n",
    "        nx.set_node_attributes(G_nx, {i: a for i, a in enumerate(attributes[0])})\n",
    "        nx.set_node_attributes(G_nx, {i + n0: a for i, a in enumerate(attributes[1])})\n",
    "        nx.set_node_attributes(G_nx, {i: {'bipartite': 0} for i in range(n0)})\n",
    "        nx.set_node_attributes(G_nx, {i + n0: {'bipartite': 1} for i in range(n1)})\n",
    "        return G_nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24716/4058704425.py:1: DtypeWarning: Columns (13,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('/home/ag16115/Documents/phd/codebase_data/activity_data.csv', sep = '\\t', on_bad_lines='skip')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/home/ag16115/Documents/phd/codebase_data/activity_data.csv', sep = '\\t', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, attributes = graph_from_dataframe(data, [['Company', 'Tender'],['Company', 'Buyer'],['Company', 'Item']], join_token='::')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subgraph_attributes = [\n",
    "#     [{'partition': 'Company'},{'partition': 'Buyer'}],\n",
    "#     {'partition': 'Buyer'}\n",
    "# ]\n",
    "\n",
    "subgraph_attributes = [\n",
    "    {'partition': 'Company'},\n",
    "    {'partition': 'Buyer'}\n",
    "]\n",
    "subgraph_A, subgraph_attributes  = find_subgraph(A, attributes,subgraph_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_dilation = symmetric_dilation(subgraph_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_A, cc_attributes = find_connected_components(subgraph_A, subgraph_attributes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
